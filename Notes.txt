GENERAL

1. Use appropriate weights initialization methods depending on the activation function for the layer
(https://medium.com/techspace-usict/normalization-techniques-in-deep-neural-networks-9121bf100d8)
2. Wrap the normalization functions into objects to save values for un-normalization (deserialization)
3. Add methods of formating input data
4. Do something with current interfaces: apply types to methods to make sure that only specific activations, norm., and losses are used.
5. Add keybind to exit/pause training at any moment (would require intoduction of asynchronous processes (like it wasn't obvious from the beginning)).

OPTIMIZATION

1. Asynchronous processes

TESTING

1. 